{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Osp3607nFu9G"
      },
      "source": [
        "# Pipeline for YOLOv8 + DeepSORT tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sk3Z04aSY3E6",
        "outputId": "5c896040-20ee-42b6-d1c7-211dd3c8039f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/macjanine/Documents/Studium/Master/3.Semester/small-toys-object-tracking/YOLOv8_Deepsort/Multiple-Object-Tracking\n"
          ]
        }
      ],
      "source": [
        "%cd Multiple-Object-Tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-OPwVAdY6ug",
        "outputId": "4f3409e3-6554-476e-9560-bd246fafe5d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.4.5 ðŸš€ Python-3.11.14 torch-2.9.1 CPU (Apple M2)\n",
            "Setup complete âœ… (8 CPUs, 16.0 GB RAM, 226.3/228.3 GB disk)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model path\n",
        "yolo_model_path = 'best6.pt'\n",
        "siamese_model_path = 'model640.pt'\n",
        "\n",
        "# Video input and output paths\n",
        "video_path = 'output_10fps.mp4'\n",
        "video_out_path = 'pred_10fps.mp4'\n",
        "\n",
        "# Detections file\n",
        "filename = 'detections_10fps.txt'\n",
        "tracking_file = 'tracking_10fps.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOMdtN8QewwF",
        "outputId": "cf17080b-1eea-4c77-8482-1f5bf2d4d103"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 640x384 4 hexbugs, 93.0ms\n",
            "Speed: 2.3ms preprocess, 93.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
            "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 640x384 4 hexbugs, 81.2ms\n",
            "Speed: 1.6ms preprocess, 81.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 4 hexbugs, 82.5ms\n",
            "Speed: 1.4ms preprocess, 82.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 4 hexbugs, 78.5ms\n",
            "Speed: 2.1ms preprocess, 78.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 7 hexbugs, 93.5ms\n",
            "Speed: 1.5ms preprocess, 93.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 4 hexbugs, 85.0ms\n",
            "Speed: 1.9ms preprocess, 85.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 4 hexbugs, 89.3ms\n",
            "Speed: 2.2ms preprocess, 89.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 5 hexbugs, 76.9ms\n",
            "Speed: 1.2ms preprocess, 76.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 4 hexbugs, 84.1ms\n",
            "Speed: 1.7ms preprocess, 84.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 4 hexbugs, 77.0ms\n",
            "Speed: 1.5ms preprocess, 77.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 4 hexbugs, 167.1ms\n",
            "Speed: 1.5ms preprocess, 167.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 4 hexbugs, 78.0ms\n",
            "Speed: 2.1ms preprocess, 78.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        }
      ],
      "source": [
        "# YOLOv8 detection\n",
        "yolo = YOLO(yolo_model_path)\n",
        "\n",
        "# Open video file\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "ret, frame = cap.read()\n",
        "\n",
        "# Initialize video writer\n",
        "cap_out = cv2.VideoWriter(video_out_path, cv2.VideoWriter_fourcc(*'MP4V'), cap.get(cv2.CAP_PROP_FPS),\n",
        "                          (frame.shape[1], frame.shape[0]))\n",
        "\n",
        "detection_threshold = 0.5\n",
        "frame_number = -1\n",
        "\n",
        "# Open a text file to save detections\n",
        "with open(filename, 'w') as f:\n",
        "    while ret:\n",
        "        frame_number += 1\n",
        "\n",
        "        # Perform object detection using YOLOv8\n",
        "        results = yolo.predict(frame)\n",
        "\n",
        "        # Collect detections\n",
        "        detections = []\n",
        "        for result in results:\n",
        "            for r in result.boxes.data.tolist():\n",
        "                x1, y1, x2, y2, score, class_id = r\n",
        "                x1, x2 = int(x1), int(x2)\n",
        "                y1, y2 = int(y1), int(y2)\n",
        "                class_id = int(class_id)\n",
        "                if score > detection_threshold:\n",
        "                    width = x2 - x1\n",
        "                    height = y2 - y1\n",
        "                    center_x = x1 + width // 2\n",
        "                    center_y = y1 + height // 2\n",
        "                    detections.append([center_x, center_y, width, height, score])\n",
        "                    # Save detection to text file\n",
        "                    f.write(f'{frame_number},-1,{center_x},{center_y},{width},{height},{score},-1,-1,-1\\n')\n",
        "        # Write the frame to the output video\n",
        "        cap_out.write(frame)\n",
        "\n",
        "        # Read the next frame\n",
        "        ret, frame = cap.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/macjanine/Documents/Studium/Master/3.Semester/small-toys-object-tracking/YOLOv8_Deepsort/Multiple-Object-Tracking/object_tracking\n"
          ]
        }
      ],
      "source": [
        "cd object_tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: [{'coords': [285.0, 1270.0, 52.0, 53.0], 'conf': 0.7700116634368896}, {'coords': [688.0, 669.0, 50.0, 48.0], 'conf': 0.710455596446991}, {'coords': [162.0, 685.0, 49.0, 50.0], 'conf': 0.6211811304092407}, {'coords': [278.0, 680.0, 45.0, 42.0], 'conf': 0.539483904838562}], 1: [{'coords': [656.0, 1736.0, 55.0, 53.0], 'conf': 0.684565544128418}, {'coords': [681.0, 795.0, 50.0, 50.0], 'conf': 0.6642363667488098}, {'coords': [175.0, 658.0, 44.0, 44.0], 'conf': 0.561223566532135}], 2: [{'coords': [709.0, 1729.0, 55.0, 55.0], 'conf': 0.6755041480064392}, {'coords': [658.0, 842.0, 49.0, 49.0], 'conf': 0.6286309361457825}, {'coords': [250.0, 670.0, 47.0, 45.0], 'conf': 0.6119263172149658}, {'coords': [164.0, 658.0, 44.0, 43.0], 'conf': 0.5406264662742615}], 3: [{'coords': [121.0, 658.0, 48.0, 47.0], 'conf': 0.6995590925216675}, {'coords': [644.0, 912.0, 45.0, 47.0], 'conf': 0.646828830242157}, {'coords': [250.0, 1550.0, 49.0, 48.0], 'conf': 0.5664522051811218}, {'coords': [256.0, 670.0, 46.0, 46.0], 'conf': 0.5230491757392883}], 4: [{'coords': [659.0, 1118.0, 48.0, 48.0], 'conf': 0.658001184463501}, {'coords': [576.0, 981.0, 47.0, 49.0], 'conf': 0.6494605541229248}, {'coords': [237.0, 668.0, 47.0, 44.0], 'conf': 0.5201123356819153}, {'coords': [119.0, 663.0, 49.0, 48.0], 'conf': 0.5074824094772339}], 5: [{'coords': [506.0, 979.0, 51.0, 51.0], 'conf': 0.6904644966125488}, {'coords': [534.0, 764.0, 52.0, 52.0], 'conf': 0.6889735460281372}, {'coords': [122.0, 655.0, 48.0, 46.0], 'conf': 0.657897412776947}], 6: [{'coords': [581.0, 982.0, 52.0, 51.0], 'conf': 0.6494794487953186}, {'coords': [122.0, 665.0, 51.0, 50.0], 'conf': 0.6139914393424988}, {'coords': [307.0, 681.0, 50.0, 48.0], 'conf': 0.5749251246452332}, {'coords': [240.0, 661.0, 49.0, 47.0], 'conf': 0.5056918859481812}], 7: [{'coords': [597.0, 1028.0, 50.0, 49.0], 'conf': 0.7005020976066589}, {'coords': [120.0, 664.0, 49.0, 48.0], 'conf': 0.680916965007782}, {'coords': [288.0, 710.0, 47.0, 48.0], 'conf': 0.6419596076011658}, {'coords': [261.0, 662.0, 49.0, 48.0], 'conf': 0.5872974395751953}], 8: [{'coords': [598.0, 667.0, 48.0, 49.0], 'conf': 0.709409236907959}, {'coords': [123.0, 658.0, 45.0, 45.0], 'conf': 0.7058740258216858}, {'coords': [421.0, 786.0, 49.0, 48.0], 'conf': 0.6696857213973999}, {'coords': [538.0, 955.0, 49.0, 48.0], 'conf': 0.5884300470352173}], 9: [{'coords': [122.0, 655.0, 45.0, 45.0], 'conf': 0.7053561806678772}, {'coords': [599.0, 906.0, 48.0, 50.0], 'conf': 0.6765668988227844}, {'coords': [704.0, 848.0, 48.0, 48.0], 'conf': 0.6696164608001709}, {'coords': [463.0, 838.0, 52.0, 50.0], 'conf': 0.5567130446434021}], 10: [{'coords': [647.0, 1429.0, 50.0, 49.0], 'conf': 0.7487131953239441}, {'coords': [121.0, 658.0, 45.0, 45.0], 'conf': 0.6826568841934204}, {'coords': [477.0, 834.0, 43.0, 42.0], 'conf': 0.6360899209976196}, {'coords': [605.0, 1020.0, 46.0, 45.0], 'conf': 0.5894764065742493}], 11: [{'coords': [431.0, 1600.0, 51.0, 51.0], 'conf': 0.6880640387535095}, {'coords': [121.0, 656.0, 46.0, 45.0], 'conf': 0.6733826994895935}, {'coords': [527.0, 1037.0, 44.0, 45.0], 'conf': 0.5444639921188354}]}\n",
            "Deep sort model loaded from path:  ../model640.pt\n",
            "1\n",
            "[[656.0, 1736.0, 55.0, 53.0], [681.0, 795.0, 50.0, 50.0], [175.0, 658.0, 44.0, 44.0]]\n",
            "[[        656        1736          55          53]\n",
            " [        681         795          50          50]\n",
            " [        175         658          44          44]]\n",
            "[    0.68457     0.66424     0.56122]\n",
            "2\n",
            "[[709.0, 1729.0, 55.0, 55.0], [658.0, 842.0, 49.0, 49.0], [250.0, 670.0, 47.0, 45.0], [164.0, 658.0, 44.0, 43.0]]\n",
            "[[        709        1729          55          55]\n",
            " [        658         842          49          49]\n",
            " [        250         670          47          45]\n",
            " [        164         658          44          43]]\n",
            "[     0.6755     0.62863     0.61193     0.54063]\n",
            "3\n",
            "[[121.0, 658.0, 48.0, 47.0], [644.0, 912.0, 45.0, 47.0], [250.0, 1550.0, 49.0, 48.0], [256.0, 670.0, 46.0, 46.0]]\n",
            "[[        121         658          48          47]\n",
            " [        644         912          45          47]\n",
            " [        250        1550          49          48]\n",
            " [        256         670          46          46]]\n",
            "[    0.69956     0.64683     0.56645     0.52305]\n",
            "4\n",
            "[[659.0, 1118.0, 48.0, 48.0], [576.0, 981.0, 47.0, 49.0], [237.0, 668.0, 47.0, 44.0], [119.0, 663.0, 49.0, 48.0]]\n",
            "[[        659        1118          48          48]\n",
            " [        576         981          47          49]\n",
            " [        237         668          47          44]\n",
            " [        119         663          49          48]]\n",
            "[      0.658     0.64946     0.52011     0.50748]\n",
            "5\n",
            "[[506.0, 979.0, 51.0, 51.0], [534.0, 764.0, 52.0, 52.0], [122.0, 655.0, 48.0, 46.0]]\n",
            "[[        506         979          51          51]\n",
            " [        534         764          52          52]\n",
            " [        122         655          48          46]]\n",
            "[    0.69046     0.68897      0.6579]\n",
            "6\n",
            "[[581.0, 982.0, 52.0, 51.0], [122.0, 665.0, 51.0, 50.0], [307.0, 681.0, 50.0, 48.0], [240.0, 661.0, 49.0, 47.0]]\n",
            "[[        581         982          52          51]\n",
            " [        122         665          51          50]\n",
            " [        307         681          50          48]\n",
            " [        240         661          49          47]]\n",
            "[    0.64948     0.61399     0.57493     0.50569]\n",
            "7\n",
            "[[597.0, 1028.0, 50.0, 49.0], [120.0, 664.0, 49.0, 48.0], [288.0, 710.0, 47.0, 48.0], [261.0, 662.0, 49.0, 48.0]]\n",
            "[[        597        1028          50          49]\n",
            " [        120         664          49          48]\n",
            " [        288         710          47          48]\n",
            " [        261         662          49          48]]\n",
            "[     0.7005     0.68092     0.64196      0.5873]\n",
            "8\n",
            "[[598.0, 667.0, 48.0, 49.0], [123.0, 658.0, 45.0, 45.0], [421.0, 786.0, 49.0, 48.0], [538.0, 955.0, 49.0, 48.0]]\n",
            "[[        598         667          48          49]\n",
            " [        123         658          45          45]\n",
            " [        421         786          49          48]\n",
            " [        538         955          49          48]]\n",
            "[    0.70941     0.70587     0.66969     0.58843]\n",
            "9\n",
            "[[122.0, 655.0, 45.0, 45.0], [599.0, 906.0, 48.0, 50.0], [704.0, 848.0, 48.0, 48.0], [463.0, 838.0, 52.0, 50.0]]\n",
            "[[        122         655          45          45]\n",
            " [        599         906          48          50]\n",
            " [        704         848          48          48]\n",
            " [        463         838          52          50]]\n",
            "[    0.70536     0.67657     0.66962     0.55671]\n",
            "10\n",
            "[[647.0, 1429.0, 50.0, 49.0], [121.0, 658.0, 45.0, 45.0], [477.0, 834.0, 43.0, 42.0], [605.0, 1020.0, 46.0, 45.0]]\n",
            "[[        647        1429          50          49]\n",
            " [        121         658          45          45]\n",
            " [        477         834          43          42]\n",
            " [        605        1020          46          45]]\n",
            "[    0.74871     0.68266     0.63609     0.58948]\n",
            "11\n",
            "[[431.0, 1600.0, 51.0, 51.0], [121.0, 656.0, 46.0, 45.0], [527.0, 1037.0, 44.0, 45.0]]\n",
            "[[        431        1600          51          51]\n",
            " [        121         656          46          45]\n",
            " [        527        1037          44          45]]\n",
            "[    0.68806     0.67338     0.54446]\n",
            "12\n",
            "13\n"
          ]
        }
      ],
      "source": [
        "from test_on_video import get_dict, get_gt, deepsort_rbc\n",
        "import numpy as np\n",
        "\n",
        "# Load detections for the video. Options available: yolo, ssd, and mask-rcnn\n",
        "gt_dict = get_dict(\"../\"+filename)\n",
        "print(gt_dict)\n",
        "\n",
        "tmp_cap = cv2.VideoCapture(\"../\"+video_path)\n",
        "tmp_shape = tmp_cap.read()[1].shape\n",
        "\n",
        "cap = cv2.VideoCapture(\"../\"+video_path)\n",
        "\n",
        "# An optional mask for the given video, to focus on the road.\n",
        "# mask = get_mask('roi.jpg')\n",
        "\n",
        "# Initialize deep sort.\n",
        "deepsort = deepsort_rbc(wt_path=\"../\"+siamese_model_path)\n",
        "\n",
        "frame_id = 1\n",
        "\n",
        "# mask = np.expand_dims(mask, 2)\n",
        "# mask = np.repeat(mask, 3, 2)\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(\"../\"+video_out_path, fourcc, 15.0, (tmp_shape[1], tmp_shape[0]))\n",
        "\n",
        "# Open a text file to write ID and bounding boxes\n",
        "with open(\"../\"+tracking_file, 'w') as f:\n",
        "    while True:\n",
        "        print(frame_id)\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            frame_id += 1\n",
        "            break\n",
        "\n",
        "        # frame = frame * mask\n",
        "        frame = frame.astype(np.uint8)\n",
        "\n",
        "        # Here it gets info for each frame\n",
        "        try:\n",
        "            detections, out_scores = get_gt(frame, frame_id, gt_dict)\n",
        "            print(detections)\n",
        "        except:\n",
        "            frame_id += 1\n",
        "            continue\n",
        "\n",
        "        if detections is None:\n",
        "            print(\"No dets\")\n",
        "            frame_id += 1\n",
        "            continue\n",
        "\n",
        "        detections = np.array(detections)\n",
        "        print(detections)\n",
        "        out_scores = np.array(out_scores)\n",
        "        print(out_scores)\n",
        "\n",
        "        tracker, detections_class = deepsort.run_deep_sort(frame, out_scores, detections)\n",
        "\n",
        "        for track in tracker.tracks:\n",
        "            if not track.is_confirmed() or track.time_since_update > 1:\n",
        "                continue\n",
        "\n",
        "            bbox = track.to_tlbr()  # Get the corrected/predicted bounding box\n",
        "            id_num = str(track.track_id)  # Get the ID for the particular track\n",
        "            features = track.features  # Get the feature vector corresponding to the detection\n",
        "\n",
        "            # Draw bbox from tracker\n",
        "            cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (255, 255, 255), 2)\n",
        "            cv2.putText(frame, str(id_num), (int(bbox[0]), int(bbox[1])), 0, 5e-3 * 200, (0, 255, 0), 2)\n",
        "\n",
        "            # Write ID and bounding box to the file\n",
        "            f.write(f'{frame_id},{id_num},{int(bbox[0])},{int(bbox[1])},{int(bbox[2])},{int(bbox[3])}\\n')\n",
        "\n",
        "            # Draw bbox from detector. Just to compare.\n",
        "            for det in detections_class:\n",
        "                bbox = det.to_tlbr()\n",
        "                cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (255, 255, 0), 2)\n",
        "\n",
        "        # cv2.imshow('frame', frame)\n",
        "        out.write(frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "        frame_id += 1\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "AIF1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
